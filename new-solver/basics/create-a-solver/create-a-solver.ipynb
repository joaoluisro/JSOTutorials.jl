{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a JSO compatible solver\n### João Okimoto\n\n![](../../jso.png)"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Pkg\npkg\"activate .\"\nif false\n pkg\"add NLPModels\"\n pkg\"add SolverTools\"\n pkg\"add SolverBenchmark\"\n pkg\"add Plots\"\n pkg\"add PyPlot\"\n pkg\"add LinearAlgebra\"\n pkg\"add JSOSolvers\"\nend\npkg\"instantiate\"\npkg\"status\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial covers the basics on how to create a solver compatible with the\nJuliaSmoothOptimizers format and how to perform basic benchmarking.\nLet's start off with a simple implementation of Newton's method."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using NLPModels, LinearAlgebra, SolverTools\n\nfunction newton(nlp :: AbstractNLPModel;\n                x :: AbstractVector = copy(nlp.meta.x0),\n                max_tol :: Real = √eps(eltype(x)),\n                max_time :: Float64 = 30.0,\n                max_iter :: Int = 100)\n\n\tfx = obj(nlp, x)\n\t∇fx = grad(nlp, x)\n\tnrmgrad = norm(∇fx)\n\t∇²fx = Symmetric(hess(nlp, x), :L)\n\n  T = eltype(x)\n  k = 0\n  el_time = 0.0\n  start_time = time()\n  tired = el_time > max_time || k ≥ max_iter\n  optimal = nrmgrad < max_tol\n\n  @info log_header([:iter, :f, :nrmgrad], [Int, T, T], hdr_override=Dict(:f => \"f(x)\", :nrmgrad => \"‖∇f(x)‖\"))\n\n  while !(optimal || tired)\n\n    @info log_row(Any[k, fx, nrmgrad])\n\n    newton_step = -∇²fx\\∇fx\n    d = dot(step, -∇fx) < 0 ? newton_step : -∇fx\n    t = one(T)\n    α = 0.5\n\t\tslope = dot(∇fx, t*d)\n\t\txt = x + t*d\n\t\tft = obj(nlp, xt)\n\n    while ft > fx + α * slope\n      t *= 0.5\n\t\t\txt = x + t*d\n\t\t\tft = obj(nlp, xt)\n\t\t\tslope =  dot(∇fx, t*d)\n    end\n\n    x += t*d\n\n\t\tfx = obj(nlp, x)\n    ∇fx = grad(nlp, x)\n    nrmgrad = norm(∇fx)\n    ∇²fx = Symmetric(hess(nlp, x), :L)\n\n\t\tk += 1\n    el_time = time() - start_time\n    tired = el_time > max_time || k ≥ max_iter\n    optimal = nrmgrad < max_tol\n  end\n\n  if optimal\n    status =:first_order\n  elseif tired\n    if k ≥ max_iter\n      status =:max_iter\n    else\n      status =:max_time\n    end\n  else\n    status =:unknown\n  end\n\n  return GenericExecutionStats(status, nlp, solution=x, objective=fx,\n                               iter = k, elapsed_time = el_time)\n\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see in the example above, our `newton` solver has a few important\nfeatures:\n- It receives the **JSO Standard input**, an **AbtractNLPModel**, part of the [NLPModels](https://github.com/JuliaSmoothOptimizers/NLPModels.jl) package.\n- Derivatives are computed according to the **AbstractNLPModel** API using the `hess` and `grad` functions.\n- It returns the **JSO Standard output**, a **GenericExecutionStats**, part of the [SolverTools](https://github.com/JuliaSmoothOptimizers/SolverTools.jl) package.\n\nBoth input and output are important when interacting with other JSO packages.\nAn **AbstractNLPModel** is the main structure of the problem, as it contains\ndetails regarding its description (i.e. function to be minimized, starting point,\nnumber of variables, etc.), while a **GenericExecutionStats** is responsible for\ncarrying information over how the problem was solved (i.e. number of iterations,\ntime elapsed, number of function evaluations, etc.).\n\nAnother important thing to highlight, is that we'll be using the **ADNLPModel**\nstruct to run our solver. **ADNLPModel** is a kind of **AbstractNLPModel**, that\nuses [ForwardDiff](https://github.com/JuliaDiff/ForwardDiff.jl) to compute\nderivatives.\n\nWhen creating a new JSO compatible solver, it's also important to manipulate\nthe output data to match that of **GenericExecutionStats**. The `status`\nattribute tells us about the result of the optimization given our input problem.\nIt is possible that the number of iterations has exceed the maximum limit,\nor the time it took for it to solve was greater than allowed. Either way, the ``status`` is an\nimportant attribute when benchmarking and testing, as it allows the user to keep\ntrack of how a solver behaves over a specific problem. It is possible to list\nall the currently acceptable statuses by running `SolverTools.show_statuses()`"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using SolverTools\n\tSolverTools.show_statuses()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to run our solver, we simply need to create a optimization problem"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f(x) = (x[1]^2 + x[2]^2)^2\nproblem = ADNLPModel(f, [1.0,2.0])\noutput = newton(problem)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The information regarding the solution of the problem is stored in `output`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a solver in hands, we can start to do more interesting things, such as\nbenchmarking and comparing our `newton` method to other solvers. Since JSO\ncontains a lot of useful packages, we'll be using a collection of those to make\nour comparison easier. The packages we'll be using are [SolverTools](https://github.com/JuliaSmoothOptimizers/SolverTools.jl)\nand [SolverBenchmarks](https://github.com/JuliaSmoothOptimizers/SolverBenchmark.jl).\nThe first is a package that provides tools for developing solvers, and the last,\nis a package that's designed for manipulating DataFrames that contain statistics\nregarding the execution of a specific solver given a set of problems.\n\nLet us compare our `newton` method to a solver contained in the\n[JSOSolvers](https://github.com/JuliaSmoothOptimizers/JSOSolvers.jl) package,\nnamely `lbfgs`, a line-search solver using limited memory BFGS updates.\nFirstly, we'll need to gather the data regarding each solver."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using SolverBenchmark, JSOSolvers\nsolvers = Dict(:newton=>newton, :lbfgs=>lbfgs)\nf1(x) = x[1]^2 + x[2]^2\nf2(x) = (1 - x[1])^2 + 100(x[2] - x[1]^2)^2\nf3(x) = x[1]^2 + x[2] - 11 + (x[1] + x[2]^2 - 7)^2\nf4(x) = 0.26 * (x[1]^2 + x[2]^2) - 0.48 * x[1] * x[2]\ntest_functions = [f1, f2, f3, f4]\nproblems = (ADNLPModel(i, 2*ones(2), name=\"Problem $i\") for i in test_functions)\nstats = bmark_solvers(solvers, problems)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ``bmark_solvers`` function is part of the **SolverTools** package, and\nruns our solver on a set of problems given by `problems`, in our case `f1`, `f2`\n, `f3` and `f4`. Lastly, it returns a dictionary `solver => DataFrame`, where\n`DataFrame` is the execution data of that solver in the problems, that we can manipulate using\n**SolverBenchmarks**.\n\nNext, let's create a latex table with the data we just gathered"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "open(\"newton.tex\", \"w\") do io\n  latex_table(io, stats[:newton], cols = [:name, :status, :objective, :elapsed_time, :iter])\nend\nopen(\"lbfgs.tex\", \"w\") do io\n  latex_table(io, stats[:lbfgs], cols = [:name, :status, :objective, :elapsed_time, :iter])\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "That will give us a nicely formatted table that we can just plug into our\nlatex code. It's also possible to create the table in the markdown format."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "markdown_table(stdout, stats[:newton],cols = [:name,:status,:objective,:elapsed_time,:iter])\n\nmarkdown_table(stdout, stats[:lbfgs],cols = [:name,:status,:objective,:elapsed_time,:iter])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Either way, our tables should look something like this:\n### LBFGS\n\n```\n|       name |      status | objective | elapsed_time | iter |\n|------------|-------------|-----------|--------------|------|\n| Problem f1 | first_order |   0.0e+00 |      1.2e+00 |    2 |\n| Problem f2 | first_order |   1.3e-16 |      7.0e-04 |   25 |\n| Problem f3 | first_order |  -8.4e+00 |      3.7e-04 |    8 |\n| Problem f4 | first_order |   1.2e-28 |      9.8e-05 |    2 |\n```\n### Newton\n\n```\n|       name |      status | objective | elapsed_time | iter |\n|------------|-------------|-----------|--------------|------|\n| Problem f1 | first_order |   0.0e+00 |      6.1e-01 |    2 |\n| Problem f2 | first_order |   0.0e+00 |      1.5e-01 |   17 |\n| Problem f3 | first_order |  -8.4e+00 |      1.5e-01 |   16 |\n| Problem f4 | first_order |   5.6e-62 |      1.4e-01 |    2 |\n```\nIn the latex format\n\n![](lbfgs.svg)\n\n![](newton.svg)\n\nTo create a performance profile, we use the **Plots** package, along with the\ndesired framework. The profiles are drawn using [BenchmarkProfiles] through an\ninterface in SolverBenchmark to use `stats`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\npyplot()\nperformance_profile(stats, df->df.elapsed_time)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.3.1"
    },
    "kernelspec": {
      "name": "julia-1.3",
      "display_name": "Julia 1.3.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
